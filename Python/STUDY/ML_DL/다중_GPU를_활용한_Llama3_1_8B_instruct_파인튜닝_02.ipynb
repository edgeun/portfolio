{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebdECv-osoz2"
      },
      "outputs": [],
      "source": [
        "## 다중 GPU를 활용한 Llama3.1-8B-instruct 파인튜닝\n",
        "## 실습 교재: 한권으로 끝내는 실전 LLM 파인튜닝"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VhGApGOqH_z",
        "outputId": "25b63e8d-54d2-473a-9529-782a1ec07344",
        "scrolled": true,
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llm-finetuning'...\n",
            "remote: Enumerating objects: 15641, done.\u001b[K\n",
            "remote: Counting objects: 100% (15641/15641), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14543/14543), done.\u001b[K\n",
            "remote: Total 15641 (delta 1096), reused 15637 (delta 1094), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (15641/15641), 6.75 MiB | 20.20 MiB/s, done.\n",
            "Resolving deltas: 100% (1096/1096), done.\n",
            "Collecting transformers==4.44.2 (from -r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1))\n",
            "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==2.18.0 (from -r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2))\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting accelerate==0.29.3 (from -r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3))\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting evaluate==0.4.1 (from -r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 4))\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting bitsandbytes==0.43.1 (from -r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 5))\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: huggingface_hub>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 6)) (0.28.1)\n",
            "Collecting trl==0.8.6 (from -r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 7))\n",
            "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting peft==0.10.0 (from -r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 8))\n",
            "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (0.19.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1)) (0.5.2)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1))\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2)) (17.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2))\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2)) (2.2.2)\n",
            "Collecting xxhash (from datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2))\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2)) (3.11.12)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3)) (2.5.1+cu124)\n",
            "Collecting responses<0.19 (from evaluate==0.4.1->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 4))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting tyro>=0.5.11 (from trl==0.8.6->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 7))\n",
            "  Downloading tyro-0.9.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.23.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 9)) (3.5.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (4.25.6)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2)) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3)) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.8.6->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 7)) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.8.6->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 7)) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.8.6->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 7))\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.8.6->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 7)) (4.4.1)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 2)) (2025.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 10)) (5.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6->-r /content/llm-finetuning/chapter3/3.5/requirements.txt (line 7)) (0.1.2)\n",
            "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.14-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: xxhash, shtab, pyarrow-hotfix, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, responses, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, tyro, tokenizers, nvidia-cusolver-cu12, transformers, datasets, evaluate, bitsandbytes, accelerate, trl, peft\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.2\n",
            "    Uninstalling transformers-4.48.2:\n",
            "      Successfully uninstalled transformers-4.48.2\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.3.0\n",
            "    Uninstalling accelerate-1.3.0:\n",
            "      Successfully uninstalled accelerate-1.3.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.29.3 bitsandbytes-0.43.1 datasets-2.18.0 dill-0.3.8 evaluate-0.4.1 fsspec-2024.2.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.10.0 pyarrow-hotfix-0.6 responses-0.18.0 shtab-1.7.1 tokenizers-0.19.1 transformers-4.44.2 trl-0.8.6 tyro-0.9.14 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/wikibook/llm-finetuning\n",
        "!pip install -r /content/llm-finetuning/chapter3/3.5/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ubCmmfPJ1jUl"
      },
      "outputs": [],
      "source": [
        "## 필요한 라이브러리 불러오기\n",
        "import logging\n",
        "from dataclasses import dataclass, field\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl.commands.cli_utils import  TrlParser\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    set_seed,\n",
        ")\n",
        "\n",
        "from trl import setup_chat_format, SFTTrainer\n",
        "from peft import LoraConfig\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from huggingface_hub import login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTA2FGlN2KPf"
      },
      "outputs": [],
      "source": [
        "## 허깅페이스 로그인\n",
        "login(\n",
        "    token=\"****\",\n",
        "    add_to_git_credential=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4wEID3DvZrh"
      },
      "source": [
        "### 데이터셋 준비\n",
        "1. 데이터셋 불러오기\n",
        "- 허깅페이스 이준범(beomi)님의 'KoAlpaca-v1.1a 데이터셋' 활용\n",
        "- 네이버 지식인의 베스트 질문들을 크롤링해 수집된 데이터로, 질문 제목, 질문 본문, 그리고 채택된 답변 본문을 포함하고 있다.\n",
        "\n",
        "2. 시스템 프롬프트 정의\n",
        "- 모델이 답변을 생성할 때 사용할 기본 시스템 프롬프트를 설정이는 학습 데이터의 messages 필드에 추가\n",
        "\n",
        "3. 데이터셋 변환\n",
        "- 각 샘플을 시스템 프롬프트, 사용자 질문(instruction), 그리고 정답(output)으로 구성된 대화 형태로 변환\n",
        "\n",
        "4. 불필요한 열 제거 및 데이터셋 분리\n",
        "- 학습에 필요하지 않은 열을 제거, 데이터셋을 학습용(train)과 테스트용(test)으로 9:1 비율로 분리\n",
        "\n",
        "5. JSON 형식으로 저장\n",
        "- 변환된 데이터셋을 JSON 파일로 저장하여 재사용성을 확보"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372,
          "referenced_widgets": [
            "edb8f2f44d75474fa65a265db064b21b",
            "4784724a873c4917ae087733643b9fcc",
            "ba181c4d484f4f72a6001abf0db6d823",
            "74482e31fa4f4e328f77561f87713e8e",
            "5afd7f33b63e4f138554a933585f246d",
            "ace092e6a80043f4ab0856da53c0fdfe",
            "1cc1b2fd72c54ceb90f419bf16a73260",
            "ccb8b35ff55542a08c1823101e00c36a",
            "b4e14f675cc64640b01d8c2f761dd172",
            "edd52e9d9f24474f84c340c9b4a76300",
            "89747754239c410e9dbd3352296a211e",
            "2232b0efcbd44ebd990adcb7e44266cc",
            "91855107ac224dce93a3dc7e8e663056",
            "e28dc99742fc4d188a19b03bbb4c3a55",
            "b313ea122dc747aba1e9254d82ea4683",
            "8bbc4ee4e7b64a07b333009ff4e57643",
            "2fb79c60c76d402ebc38d7debc672df4",
            "6ecd19b4a65d48d89fa4841d8de3450b",
            "3ad6971ff6cd4d2bbe5a4ee1f1a0e296",
            "96a51006e70245309565198d90e3df3a",
            "df65b0d800464b1db87a2d72350ccd42",
            "6d2c0784eb0a41f2851cef60709c312e",
            "1a247bdd210745938408c462c53fa465",
            "40484204235a480a8c3339e6d53a4594",
            "8bbe4902e9a64468855bb27b43f0fb6a",
            "82f7d6e51a33460380b06d5d3383ea10",
            "42026c5458694554bc3c3c0e542e7a48",
            "df0a3375c62b4a41937d98d314846052",
            "3911b3863b8847d3b9405e723d2f699c",
            "c0a63384654347519ecc4d4bb4c36e7b",
            "283467d8acf142b4af3415c47e007ade",
            "b250960e874e409c95a2e3a98dc8eea3",
            "f3bcee2835824b129a48deb1764ab82a",
            "ccd13dbc9e544f64b145a452f542140a",
            "7a13e8eb621a4813a8907a8f43ed0ccd",
            "9e814e996f0b4751922b39cca14fad42",
            "8f1f1f79c9c243659e7a0eb145d91caf",
            "66e10d9d5562441a810b7ea1605f4354",
            "52f5e86b327c42caae8b66d609607ca8",
            "bad31a37d40d46baaab0bec2b8398367",
            "5373135bed4e42dcbadd36d0ce9e1cf1",
            "708c55b46cee4e70a07b96db34987303",
            "6f8adf950ad141ba958bdd5feac4bffe",
            "4929971bba574fb1b1ef4ee63f924fe7",
            "53df7fd0342645869914c62668323bf2",
            "324d2fb48a8b49fc99aac690da6c1dd5",
            "eac5b168727445f69cb6a7b82947d871",
            "661d34b3f0964e6db28aadb7a0913fdc",
            "3d76292512624773b095c940b55c9c9a",
            "47bba5964d98412ca241ebf8c8dd3fba",
            "c54b56bf9ba746a388d54c3df6f36c84",
            "b33c134019a74eaca31344110bb3d511",
            "ddeea3999ef24ff09ed597c4c8caca4f",
            "2b87066f213a4b66b677e65d1462629e",
            "239add5bba35438180d056c5d6e4a3f7",
            "08a32984cb3543bda6eb6fbc4afab9d3",
            "edf5e36a239147acad70b12f0b491973",
            "fae95b24e0bd43f290991a2b445b488b",
            "125cb531f7da4e1eae4936839f632429",
            "7af2d847ab6d423aaff23fa474a8af1e",
            "a81e006a9a434b0492fda4a7f4218854",
            "6c8b5105e5a145a8a832c6d25571d445",
            "ab66a401e02f4383adea71df2e17f287",
            "d533b5a5a866427590cfffb81736e2ea",
            "14d6ae6cd5bc4bbe8338a1ab0dcbcb18",
            "59309e057ca74f3b9b015a0bc583d0f4"
          ]
        },
        "id": "lEAJzOJmsdoI",
        "outputId": "dc167857-6b5f-464f-bbf0-8d021aa7e53a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edb8f2f44d75474fa65a265db064b21b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/1.75k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading data: 100%|██████████| 12.9M/12.9M [00:00<00:00, 40.0MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2232b0efcbd44ebd990adcb7e44266cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/21155 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a247bdd210745938408c462c53fa465",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/21155 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccd13dbc9e544f64b145a452f542140a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/21155 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53df7fd0342645869914c62668323bf2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/20 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08a32984cb3543bda6eb6fbc4afab9d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "3837318"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## 데이터셋 준비\n",
        "# 1. 데이터셋 불러오기\n",
        "dataset = load_dataset(\"beomi/KoAlpaca-v1.1a\")  # 데이터 출처: 허깅페이스 이준범(beomi)님의 'KoAlpaca-v1.1a 데이터셋'  # 네이버 지식인 베스트 질문 크롤링 데이터\n",
        "\n",
        "# 2. system_prompt 변수에 AI 어시스턴트의 역할과 행동 지침을 상세히 정함\n",
        "system_prompt = \"\"\"\n",
        "\n",
        "당신은 다양한 분야의 전문가들이 제공한 지식과 정보를 바탕으로 만들어진 AI 어시스턴트입니다.\n",
        "사용자들의 질문에 대해 정확하고 유용한 답변을 제공하는 것이 당신의 주요 목표입니다.\n",
        "복잡한 주제에 대해서도 이해하기 쉽게 설명할 수 있으며, 필요한 경우 추가 정보나 관련 예시를 제공할 수 있습니다.\n",
        "항상 객관적이고 중립적인 입장을 유지하면서, 최신 정보를 반영하여 답변해 주세요.\n",
        "사용자의 질문이 불분명한 경우 추가 설명을 요청하고, 당신이 확실하지 않은 정보에 대해서는 솔직히 모른다고 말해주세요.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# 3. map 함수를 이용해 각 샘플을 시스템 프롬프트, 사용자의 지시사항, AI의 응답으로 이뤄진 chat_template 형식(대화형 데이터셋 형식)으로 변환\n",
        "train_dataset = dataset.map(\n",
        "    lambda sample:\n",
        "    { 'messages' : [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": sample['instruction']},\n",
        "        {\"role\": \"assistant\", \"content\": sample['output']}]\n",
        "                   },\n",
        ")\n",
        "\n",
        "# 4. 불필요한 컬럼들 제거  # train 데이터셋을 9:1로 훈련과 테스트 데이터 분리\n",
        "columns_to_remove = list(dataset[\"train\"].features)  # 컬럼을 지우기 위해 train 데이터셋의 컬럼 이름 리스트에 담기\n",
        "train_dataset = train_dataset.map(remove_columns=columns_to_remove,batched=False)\n",
        "train_dataset = train_dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "\n",
        "# 5. JSON 형식으로 저장\n",
        "train_dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\", force_ascii=False)\n",
        "train_dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\", force_ascii=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzM9tMBXvZri"
      },
      "source": [
        "### Llama3 대화 템플릿 설정\n",
        "- 대화 데이터를 텍스트 형식으로 변환하기 위한 템플릿\n",
        "- system, user, assistant 역할별로 메시지를 구성하여 학습 데이터에 적용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbRUpScM3TKg"
      },
      "outputs": [],
      "source": [
        "LLAMA_3_CHAT_TEMPLATE = (\n",
        "    \"{% for message in messages %}\"\n",
        "        \"{% if message['role'] == 'system' %}\"\n",
        "            \"{{ message['content'] }}\"\n",
        "        \"{% elif message['role'] == 'user' %}\"\n",
        "            \"{{ '\\n\\nHuman: ' + message['content'] +  eos_token }}\"\n",
        "        \"{% elif message['role'] == 'assistant' %}\"\n",
        "            \"{{ '\\n\\nAssistant: '  + message['content'] +  eos_token  }}\"\n",
        "        \"{% endif %}\"\n",
        "    \"{% endfor %}\"\n",
        "    \"{% if add_generation_prompt %}\"\n",
        "    \"{{ '\\n\\nAssistant: ' }}\"\n",
        "    \"{% endif %}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwC2dq0NvZrj"
      },
      "source": [
        "### 학습 파라미터 설정 (ScriptArguments 데이터 클래스)\n",
        "- 학습에 필요한 주요 설정들을 인자로 받아 CLI(Command Line Interfaces) 실행 시 유연하게 조정할 수 있도록 구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYsAVg7P2aFE"
      },
      "outputs": [],
      "source": [
        "## Llama 3.1 모델 파라미터 설정\n",
        "@dataclass  ## 데이터를 효율적으로 관리하기 위해 파이썬에서 제공하는 스크립트 설정 관리 기능인 @dataclass 사용\n",
        "# dataclass를 사용해 ScriptArguments 클래스 생성  # 클래스에서 스크립트 실행 시 필요한 여러 매개변수 관리\n",
        "class ScriptArguments:\n",
        "    dataset_path: str = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"데이터셋 파일 경로\"\n",
        "        },\n",
        "    )\n",
        "    model_name: str = field(\n",
        "    default=None, metadata={\"help\": \"SFT 학습에 사용할 모델 ID\"}\n",
        "    )\n",
        "    max_seq_length: int = field(\n",
        "        default=512, metadata={\"help\": \"SFT Trainer에 사용할 최대 시퀀스 길이\"}\n",
        "    )\n",
        "    question_key: str = field(\n",
        "    default=None, metadata={\"help\": \"지시사항 데이터셋의 질문 키\"}\n",
        "    )\n",
        "    answer_key: str = field(\n",
        "    default=None, metadata={\"help\": \"지시사항 데이터셋의 답변 키\"}\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODYVQXG4vZrj"
      },
      "source": [
        "### 모델 학습 함수\n",
        "- training_function은 실제 학습을 수행하는 핵심 함수\n",
        "\n",
        "- 학습 파라미터에서 입력받은 데이터셋 불러오기\n",
        "- template_dataset함수로 기존에 만들어 둔 train, test 데이터셋을 대화형 데이터셋으로 변경하는 전처리 진행\n",
        "- 모델 및 학습 파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wssqaMms5NLB"
      },
      "outputs": [],
      "source": [
        "## Llama 3.1 모델 학습하는 코드\n",
        "def training_function(script_args, training_args):\n",
        "    # 데이터셋 불러오기\n",
        "    train_dataset = load_dataset(\n",
        "        \"json\",\n",
        "        data_files=os.path.join(script_args.dataset_path, \"train_dataset.json\"),\n",
        "        split=\"train\",\n",
        "    )\n",
        "    test_dataset = load_dataset(\n",
        "        \"json\",\n",
        "        data_files=os.path.join(script_args.dataset_path, \"test_dataset.json\"),\n",
        "        split=\"train\",\n",
        "    )\n",
        "\n",
        "    # 토크나이저 및 데이터셋 chat_template으로 변경하기\n",
        "    tokenizer = AutoTokenizer.from_pretrained(script_args.model_name, use_fast=True)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.chat_template = LLAMA_3_CHAT_TEMPLATE\n",
        "    tokenizer.padding_side = 'right'\n",
        "\n",
        "    def template_dataset(examples):  # 기존에 만들어 둔 train, test 데이터셋을 해당 템플릿 형식으로 변환하는 함수\n",
        "        return{\"text\":  tokenizer.apply_chat_template(examples[\"messages\"], tokenize=False)}\n",
        "\n",
        "    train_dataset = train_dataset.map(template_dataset, remove_columns=[\"messages\"])\n",
        "    test_dataset = test_dataset.map(template_dataset, remove_columns=[\"messages\"])\n",
        "\n",
        "    # 데이터가 변화되었는지 확인하기 위해 2개만 출력하기\n",
        "    with training_args.main_process_first(\n",
        "        ## main_process_first()는 분산 학습 환경에서 로그 중복 기록 등 불필요한 작업을 방지하기 위해 여러 프로세스 중 메인 프로세스를 지정하여\n",
        "        ## 특정 작업을 마칠 때까지 다른 프로세스들을 대기시키는 기능\n",
        "        desc=\"Log a few random samples from the processed training set\"\n",
        "    ):\n",
        "        for index in random.sample(range(len(train_dataset)), 2):\n",
        "            print(train_dataset[index][\"text\"])\n",
        "\n",
        "    # Model 및 파라미터 설정하기\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        script_args.model_name,\n",
        "        attn_implementation=\"sdpa\",\n",
        "        ## 쿼리와 키의 내적을 계산하고, 이를 스케일링한 후 소프트맥스 함수를 적용해 값에 대한 가중치를 얻는\n",
        "        ## 트랜스포머 모델의 기본이 되는 어텐션 연산 \"SDPA\" 사용\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        use_cache=False if training_args.gradient_checkpointing else True,\n",
        "    )\n",
        "\n",
        "    if training_args.gradient_checkpointing:\n",
        "        model.gradient_checkpointing_enable()\n",
        "\n",
        "    # Train 설정\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        dataset_text_field=\"text\",\n",
        "        eval_dataset=test_dataset,\n",
        "        max_seq_length=script_args.max_seq_length,\n",
        "        tokenizer=tokenizer,\n",
        "        packing=True,\n",
        "        dataset_kwargs={\n",
        "            \"add_special_tokens\": False,\n",
        "            \"append_concat_token\": False,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    checkpoint = None\n",
        "    if training_args.resume_from_checkpoint is not None:\n",
        "        checkpoint = training_args.resume_from_checkpoint  # 이전에 중단된 학습을 이어서 진행할 수 있음\n",
        "    trainer.train(resume_from_checkpoint=checkpoint)\n",
        "\n",
        "    if trainer.is_fsdp_enabled:  # 완전 분산 데이터 병렬(FSDP) 모드가 활성화됐는지 확인\n",
        "        ## 이 모드가 활성화 되있으면, 전체 상태 사전(Full State Dict)을 저장하도록 설정\n",
        "        ## 모델의 전체 파라미터를 저장해 나중에 쉽게 불러올 수 있게 함\n",
        "        trainer.accelerator.state.fsdp_plugin.set_state_dict_type(\"FULL_STATE_DICT\")\n",
        "    trainer.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZExQIkfvZrj"
      },
      "source": [
        "### 메인 블록(전체 실행)\n",
        "- TrlParser를 사용해 스크립트 인자와 학습 인자를 파싱:\n",
        "    커맨드 라인에서 입력된 다양한 설정값들을 처리하는 역할을 함. 이후 gradient checkpointing 옵션이 활성화 되어 있다면, 재진입(reentrant) 모드를 사용하도록 설정\n",
        "- set_seed 시드값 고정으로 실습 재현성 보장\n",
        "- training_function 함수를 호출해 학습 수행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umx9beNIDsTo"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    parser = TrlParser((ScriptArguments, TrainingArguments))\n",
        "    script_args, training_args = parser.parse_args_and_config()\n",
        "\n",
        "    if training_args.gradient_checkpointing:\n",
        "        training_args.gradient_checkpointing_kwargs = {\"use_reentrant\": True}\n",
        "\n",
        "    # set seed\n",
        "    set_seed(training_args.seed)\n",
        "\n",
        "    # launch training\n",
        "    training_function(script_args, training_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpKirYrEDtO-"
      },
      "outputs": [],
      "source": [
        "## 위의 Full Finetuning 코드를 py 파일화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HqjDtYEvZrj"
      },
      "source": [
        "### 4. Llama 3.1 모델 학습 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlKU8DVPD7IU",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "## 학습 파라미터 설정 파일(yaml)과 파인튜닝 코드 파일(py)을 사용해서\n",
        "## 터미널에서 학습 진행하는 명령어를 입력하여 학습 진행  # 터미널 수행시 앞에 ! 제거\n",
        "!ACCELERATE_USE_FSDP=1 FSDP_CPU_RAM_EFFICIENT_LOADING=1 \\\n",
        "torchrun --nproc_per_node=2 \\\n",
        "./1_train_full_fine_tuning.py \\\n",
        "--config 0_full_fine_tuning_config.yaml\n",
        "\n",
        "# ACCELERATE_USE_FSDP=1: 허깅페이스의 Accelerate 라이브러리에서 FSDP(Fully Sharded Data Parallel)을 사용하겠다는 명령어, 대규모 모델을 여러 GPU에 효율적으로 분산\n",
        "# FSDP_CPU_RAM_EFFICIENT_LOADING=1: FSDP를 사용할 때 CPU RAM을 효율적으로 사용해 모델을 로딩\n",
        "# torchrun --nproc_per_node=4: 파이토치의 분산 학습을 위한 실행 도구, 각 노드(컴퓨터)에서 4개의 프로세스를 실행(4개의 GPU - 처음 런팟 설정에서 지정)\n",
        "# 1_train_full_fine_tuning.py: 실행할 파이썬 스크립트의 경로, 모델 전체 파인튜닝 수행\n",
        "# 0_full_fine_tuning_config.yaml: 파인튜닝에 사용할 설정 파일 지정, yaml 형식의 설정 파일, 학습률, 배치 크기, 에폭 수 등의 하이퍼파라미터를 사전에 정의해놓은 파일"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfUcns3KvZrk"
      },
      "source": [
        "### 5. 학습한 Llama 3.1 모델 테스트\n",
        "\n",
        "1. 모델 로드\n",
        "- llama-3.1-korean-8b-hf 모델을 bfloat16 형식으로 로드하고 GPU/CPU 자동 할당 설정\n",
        "\n",
        "2. 테스트 데이터셋 로드\n",
        "- test_dataset.json에서 JSON 데이터를 로드하고 랜덤 메시지 샘플링\n",
        "\n",
        "3. 토크나이저 설정\n",
        "- eos_token을 패딩 토큰으로 설정하고 텍스트 정렬\n",
        "\n",
        "4. 응답 생성\n",
        "- temperature=0.7, top_p=0.95 설정으로 답변 생성\n",
        "- 질문, 참조 답변, 모델 생성 응답 출력\n",
        "\n",
        "5. 평가 시스템\n",
        "- Pydantic으로 평가 기준(관련성, 정확성, 완전성, 명확성, 유사성)과 평균 점수 계산\n",
        "\n",
        "6. 평가 함수\n",
        "- OpenAI API를 통해 질문/답변을 비교 평가 후 결과 반환\n",
        "\n",
        "7. 실행 예시\n",
        "- 질문/참조/모델 답변을 평가하고 결과 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1s-fHrrivZrk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from random import randint\n",
        "from datasets import load_dataset\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer\n",
        ")\n",
        "\n",
        "model_name = \"./llama-3.1-korean-8b-hf-20-epoch/checkpoint-4740\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    use_cache=False,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "test_dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=os.path.join(\"\", \"./test_dataset.json\"),\n",
        "    split=\"train\",\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'right'\n",
        "\n",
        "test_dataset = load_dataset(\"json\",\n",
        "                            split=\"train\",\n",
        "                            data_files=\"test_dataset.json\")\n",
        "\n",
        "random_index = randint(0, len(test_dataset))\n",
        "messages = test_dataset[random_index][\"messages\"][:2]\n",
        "\n",
        "terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "]\n",
        "\n",
        "input_ids = tokenizer.apply_chat_template(messages,\n",
        "                                          add_generation_prompt=True,\n",
        "                                          return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        ")\n",
        "response = outputs[0][input_ids.shape[-1]:]\n",
        "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
        "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
        "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")\n",
        "from datasets import load_dataset\n",
        "from random import randint\n",
        "\n",
        "\n",
        "# Load our test dataset\n",
        "test_dataset = load_dataset(\"json\",\n",
        "                            split=\"train\",\n",
        "                            data_files=\"test_dataset.json\")\n",
        "random_index = randint(0, len(test_dataset))\n",
        "messages = test_dataset[random_index][\"messages\"][:2]\n",
        "\n",
        "terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "]\n",
        "\n",
        "# Test on sample\n",
        "input_ids = tokenizer.apply_chat_template(messages,\n",
        "                                          add_generation_prompt=True,\n",
        "                                          return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        ")\n",
        "response = outputs[0][input_ids.shape[-1]:]\n",
        "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
        "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
        "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")\n",
        "from datasets import load_dataset\n",
        "from random import randint\n",
        "\n",
        "\n",
        "# Load our test dataset\n",
        "test_dataset = load_dataset(\"json\",\n",
        "                            split=\"train\",\n",
        "                            data_files=\"test_dataset.json\")\n",
        "random_index = randint(0, len(test_dataset))\n",
        "messages = test_dataset[random_index][\"messages\"][:2]\n",
        "\n",
        "terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "]\n",
        "\n",
        "# Test on sample\n",
        "input_ids = tokenizer.apply_chat_template(messages,\n",
        "                                          add_generation_prompt=True,\n",
        "                                          return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        ")\n",
        "response = outputs[0][input_ids.shape[-1]:]\n",
        "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
        "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
        "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")\n",
        "## 최종모델\n",
        "from datasets import load_dataset\n",
        "from random import randint\n",
        "\n",
        "\n",
        "# Load our test dataset\n",
        "test_dataset = load_dataset(\"json\",\n",
        "                            split=\"train\",\n",
        "                            data_files=\"test_dataset.json\")\n",
        "random_index = randint(0, len(test_dataset))\n",
        "messages = test_dataset[random_index][\"messages\"][:2]\n",
        "\n",
        "terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "]\n",
        "\n",
        "# Test on sample\n",
        "input_ids = tokenizer.apply_chat_template(messages,\n",
        "                                          add_generation_prompt=True,\n",
        "                                          return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        ")\n",
        "response = outputs[0][input_ids.shape[-1]:]\n",
        "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
        "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
        "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")\n",
        "from datasets import load_dataset\n",
        "from random import randint\n",
        "\n",
        "\n",
        "# Load our test dataset\n",
        "test_dataset = load_dataset(\"json\",\n",
        "                            split=\"train\",\n",
        "                            data_files=\"test_dataset.json\")\n",
        "random_index = randint(0, len(test_dataset))\n",
        "messages = test_dataset[random_index][\"messages\"][:2]\n",
        "\n",
        "terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "]\n",
        "\n",
        "# Test on sample\n",
        "input_ids = tokenizer.apply_chat_template(messages,\n",
        "                                          add_generation_prompt=True,\n",
        "                                          return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        ")\n",
        "response = outputs[0][input_ids.shape[-1]:]\n",
        "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
        "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
        "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")\n",
        "from datasets import load_dataset\n",
        "from random import randint\n",
        "\n",
        "\n",
        "# Load our test dataset\n",
        "test_dataset = load_dataset(\"json\",\n",
        "                            split=\"train\",\n",
        "                            data_files=\"test_dataset.json\")\n",
        "random_index = randint(0, len(test_dataset))\n",
        "messages = test_dataset[random_index][\"messages\"][:2]\n",
        "\n",
        "terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "]\n",
        "\n",
        "# Test on sample\n",
        "input_ids = tokenizer.apply_chat_template(messages,\n",
        "                                          add_generation_prompt=True,\n",
        "                                          return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        ")\n",
        "response = outputs[0][input_ids.shape[-1]:]\n",
        "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
        "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
        "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")\n",
        "from datasets import load_dataset\n",
        "from random import randint\n",
        "\n",
        "\n",
        "# Load our test dataset\n",
        "test_dataset = load_dataset(\"json\",\n",
        "                            split=\"train\",\n",
        "                            data_files=\"test_dataset.json\")\n",
        "random_index = randint(0, len(test_dataset))\n",
        "messages = test_dataset[random_index][\"messages\"][:2]\n",
        "\n",
        "terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "]\n",
        "\n",
        "# Test on sample\n",
        "input_ids = tokenizer.apply_chat_template(messages,\n",
        "                                          add_generation_prompt=True,\n",
        "                                          return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        ")\n",
        "response = outputs[0][input_ids.shape[-1]:]\n",
        "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
        "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
        "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")\n",
        "from datasets import load_dataset\n",
        "from random import randint\n",
        "\n",
        "\n",
        "# Load our test dataset\n",
        "test_dataset = load_dataset(\"json\",\n",
        "                            split=\"train\",\n",
        "                            data_files=\"test_dataset.json\")\n",
        "random_index = randint(0, len(test_dataset))\n",
        "messages = test_dataset[random_index][\"messages\"][:2]\n",
        "\n",
        "terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "]\n",
        "\n",
        "# Test on sample\n",
        "input_ids = tokenizer.apply_chat_template(messages,\n",
        "                                          add_generation_prompt=True,\n",
        "                                          return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        ")\n",
        "response = outputs[0][input_ids.shape[-1]:]\n",
        "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
        "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
        "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")\n",
        "from datasets import load_dataset\n",
        "from random import randint\n",
        "\n",
        "\n",
        "# Load our test dataset\n",
        "test_dataset = load_dataset(\"json\",\n",
        "                            split=\"train\",\n",
        "                            data_files=\"test_dataset.json\")\n",
        "random_index = randint(0, len(test_dataset))\n",
        "messages = test_dataset[random_index][\"messages\"][:2]\n",
        "\n",
        "terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "]\n",
        "\n",
        "# Test on sample\n",
        "input_ids = tokenizer.apply_chat_template(messages,\n",
        "                                          add_generation_prompt=True,\n",
        "                                          return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        ")\n",
        "response = outputs[0][input_ids.shape[-1]:]\n",
        "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
        "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
        "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")\n",
        "random_index = randint(0, len(test_dataset))\n",
        "messages = test_dataset[random_index][\"messages\"][:2]\n",
        "\n",
        "terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "]\n",
        "\n",
        "# Test on sample\n",
        "input_ids = tokenizer.apply_chat_template(messages,\n",
        "                                          add_generation_prompt=True,\n",
        "                                          return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        ")\n",
        "response = outputs[0][input_ids.shape[-1]:]\n",
        "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
        "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
        "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")\n",
        "\n",
        "from pydantic import BaseModel\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "# OpenAI 클라이언트 초기화\n",
        "client = OpenAI(api_key=\"****\")\n",
        "\n",
        "class Criterion(BaseModel):\n",
        "    score: int\n",
        "    explanation: str\n",
        "\n",
        "class Evaluation(BaseModel):\n",
        "    relevance: Criterion\n",
        "    accuracy: Criterion\n",
        "    completeness: Criterion\n",
        "    clarity: Criterion\n",
        "    similarity: Criterion\n",
        "    average_score: float\n",
        "\n",
        "def evaluate_qa_model(question: str, reference_answer: str, model_answer: str) -> Evaluation:\n",
        "    prompt = f\"\"\"\n",
        "질문: {question}\n",
        "참조 답변: {reference_answer}\n",
        "모델 생성 답변: {model_answer}\n",
        "\n",
        "위의 질문에 대한 두 답변을 비교 평가해주세요. 다음 기준에 따라 1-10점 사이의 점수를 매겨주세요:\n",
        "1. 관련성: 모델의 답변이 질문과 얼마나 관련이 있는가?\n",
        "2. 정확성: 모델이 제공한 정보가 참조 답변과 비교하여 얼마나 정확한가?\n",
        "3. 완전성: 모델의 답변이 질문에 대해 얼마나 포괄적인가?\n",
        "4. 명확성: 모델의 답변이 얼마나 명확하고 이해하기 쉬운가?\n",
        "5. 유사성: 모델의 답변이 참조 답변과 얼마나 유사한가?\n",
        "\n",
        "각 기준에 대한 점수와 간단한 설명을 제공해주세요. 마지막으로 전체 평균 점수를 계산해주세요.\n",
        "\"\"\"\n",
        "\n",
        "    completion = client.beta.chat.completions.parse(\n",
        "        model=\"gpt-4o-mini\",  # 또는 사용 가능한 최신 모델\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"귀하는 QA 모델 응답을 평가하는 임무를 맡은 AI 어시스턴트입니다.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        response_format=Evaluation\n",
        "    )\n",
        "\n",
        "    return completion\n",
        "\n",
        "# 사용 예시\n",
        "if __name__ == \"__main__\":\n",
        "    question = \"인공지능의 윤리적 고려사항은 무엇인가요?\"\n",
        "    reference_answer = \"인공지능의 주요 윤리적 고려사항에는 1) 프라이버시 보호: 개인 정보의 수집, 처리, 저장에 관한 문제, 2) 알고리즘 편향성 방지: 인종, 성별, 연령 등에 대한 차별 방지, 3) 투명성 확보: AI 의사결정 과정의 설명 가능성, 4) 책임성 명확화: AI 시스템의 오류나 해악에 대한 책임 소재, 5) 안전성과 보안: AI 시스템의 안전한 작동과 외부 공격으로부터의 보호, 6) 인간 통제: AI가 인간의 통제를 벗어나지 않도록 하는 것 등이 있습니다. 이러한 요소들은 AI 기술이 사회에 미치는 영향을 고려하여 신중하게 다루어져야 하며, 법적, 제도적 장치를 통해 관리되어야 합니다.\"\n",
        "\n",
        "    model_answer = \"인공지능의 윤리적 고려사항에는 프라이버시 보호, 알고리즘 편향성 방지, 투명성 확보, 책임성 명확화 등이 있습니다. 이러한 요소들은 AI 기술이 사회에 미치는 영향을 고려하여 신중하게 다루어져야 합니다.\"\n",
        "\n",
        "    evaluation = evaluate_qa_model(question, reference_answer, model_answer)\n",
        "    print(evaluation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJvLVy96vZrl",
        "outputId": "a7d424e0-888b-4978-b852-393b5c1aa551"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.3294000000000095, 5.318070000000009)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import json\n",
        "from glob import glob  # 해당 경로내 파일을 순회하는 라이브러리\n",
        "\n",
        "path = \"/content/llm-finetuning/chapter3/3.5/qa_evaluation_results\"\n",
        "\n",
        "path_list = glob(f\"{path}/*\")\n",
        "\n",
        "calculated_average_list = []\n",
        "model_average_score = []\n",
        "for path in path_list:\n",
        "    with open(path, \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    data = data[\"choices\"][0][\"message\"][\"parsed\"]\n",
        "    scores = [item['score'] for item in data.values() if isinstance(item, dict)]\n",
        "    calculated_average = sum(scores) / len(scores)\n",
        "    calculated_average_list.append(calculated_average)\n",
        "    model_average_score.append(data[\"average_score\"])\n",
        "\n",
        "mean_calculated_average= sum(calculated_average_list) / len(calculated_average_list)\n",
        "mean_model_average_score = sum(model_average_score) / len(model_average_score)\n",
        "mean_calculated_average, mean_model_average_score"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08a32984cb3543bda6eb6fbc4afab9d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edf5e36a239147acad70b12f0b491973",
              "IPY_MODEL_fae95b24e0bd43f290991a2b445b488b",
              "IPY_MODEL_125cb531f7da4e1eae4936839f632429"
            ],
            "layout": "IPY_MODEL_7af2d847ab6d423aaff23fa474a8af1e"
          }
        },
        "125cb531f7da4e1eae4936839f632429": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14d6ae6cd5bc4bbe8338a1ab0dcbcb18",
            "placeholder": "​",
            "style": "IPY_MODEL_59309e057ca74f3b9b015a0bc583d0f4",
            "value": " 3/3 [00:00&lt;00:00, 19.06ba/s]"
          }
        },
        "14d6ae6cd5bc4bbe8338a1ab0dcbcb18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a247bdd210745938408c462c53fa465": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40484204235a480a8c3339e6d53a4594",
              "IPY_MODEL_8bbe4902e9a64468855bb27b43f0fb6a",
              "IPY_MODEL_82f7d6e51a33460380b06d5d3383ea10"
            ],
            "layout": "IPY_MODEL_42026c5458694554bc3c3c0e542e7a48"
          }
        },
        "1cc1b2fd72c54ceb90f419bf16a73260": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2232b0efcbd44ebd990adcb7e44266cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91855107ac224dce93a3dc7e8e663056",
              "IPY_MODEL_e28dc99742fc4d188a19b03bbb4c3a55",
              "IPY_MODEL_b313ea122dc747aba1e9254d82ea4683"
            ],
            "layout": "IPY_MODEL_8bbc4ee4e7b64a07b333009ff4e57643"
          }
        },
        "239add5bba35438180d056c5d6e4a3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "283467d8acf142b4af3415c47e007ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b87066f213a4b66b677e65d1462629e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fb79c60c76d402ebc38d7debc672df4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "324d2fb48a8b49fc99aac690da6c1dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47bba5964d98412ca241ebf8c8dd3fba",
            "placeholder": "​",
            "style": "IPY_MODEL_c54b56bf9ba746a388d54c3df6f36c84",
            "value": "Creating json from Arrow format: 100%"
          }
        },
        "3911b3863b8847d3b9405e723d2f699c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ad6971ff6cd4d2bbe5a4ee1f1a0e296": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d76292512624773b095c940b55c9c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40484204235a480a8c3339e6d53a4594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df0a3375c62b4a41937d98d314846052",
            "placeholder": "​",
            "style": "IPY_MODEL_3911b3863b8847d3b9405e723d2f699c",
            "value": "Map: 100%"
          }
        },
        "42026c5458694554bc3c3c0e542e7a48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4784724a873c4917ae087733643b9fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ace092e6a80043f4ab0856da53c0fdfe",
            "placeholder": "​",
            "style": "IPY_MODEL_1cc1b2fd72c54ceb90f419bf16a73260",
            "value": "Downloading readme: 100%"
          }
        },
        "47bba5964d98412ca241ebf8c8dd3fba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4929971bba574fb1b1ef4ee63f924fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52f5e86b327c42caae8b66d609607ca8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5373135bed4e42dcbadd36d0ce9e1cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53df7fd0342645869914c62668323bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_324d2fb48a8b49fc99aac690da6c1dd5",
              "IPY_MODEL_eac5b168727445f69cb6a7b82947d871",
              "IPY_MODEL_661d34b3f0964e6db28aadb7a0913fdc"
            ],
            "layout": "IPY_MODEL_3d76292512624773b095c940b55c9c9a"
          }
        },
        "59309e057ca74f3b9b015a0bc583d0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5afd7f33b63e4f138554a933585f246d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "661d34b3f0964e6db28aadb7a0913fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b87066f213a4b66b677e65d1462629e",
            "placeholder": "​",
            "style": "IPY_MODEL_239add5bba35438180d056c5d6e4a3f7",
            "value": " 20/20 [00:00&lt;00:00, 20.55ba/s]"
          }
        },
        "66e10d9d5562441a810b7ea1605f4354": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c8b5105e5a145a8a832c6d25571d445": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d2c0784eb0a41f2851cef60709c312e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ecd19b4a65d48d89fa4841d8de3450b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f8adf950ad141ba958bdd5feac4bffe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "708c55b46cee4e70a07b96db34987303": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74482e31fa4f4e328f77561f87713e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edd52e9d9f24474f84c340c9b4a76300",
            "placeholder": "​",
            "style": "IPY_MODEL_89747754239c410e9dbd3352296a211e",
            "value": " 1.75k/1.75k [00:00&lt;00:00, 150kB/s]"
          }
        },
        "7a13e8eb621a4813a8907a8f43ed0ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52f5e86b327c42caae8b66d609607ca8",
            "placeholder": "​",
            "style": "IPY_MODEL_bad31a37d40d46baaab0bec2b8398367",
            "value": "Map: 100%"
          }
        },
        "7af2d847ab6d423aaff23fa474a8af1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82f7d6e51a33460380b06d5d3383ea10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b250960e874e409c95a2e3a98dc8eea3",
            "placeholder": "​",
            "style": "IPY_MODEL_f3bcee2835824b129a48deb1764ab82a",
            "value": " 21155/21155 [00:01&lt;00:00, 14534.90 examples/s]"
          }
        },
        "89747754239c410e9dbd3352296a211e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bbc4ee4e7b64a07b333009ff4e57643": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bbe4902e9a64468855bb27b43f0fb6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0a63384654347519ecc4d4bb4c36e7b",
            "max": 21155,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_283467d8acf142b4af3415c47e007ade",
            "value": 21155
          }
        },
        "8f1f1f79c9c243659e7a0eb145d91caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f8adf950ad141ba958bdd5feac4bffe",
            "placeholder": "​",
            "style": "IPY_MODEL_4929971bba574fb1b1ef4ee63f924fe7",
            "value": " 21155/21155 [00:00&lt;00:00, 30378.13 examples/s]"
          }
        },
        "91855107ac224dce93a3dc7e8e663056": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb79c60c76d402ebc38d7debc672df4",
            "placeholder": "​",
            "style": "IPY_MODEL_6ecd19b4a65d48d89fa4841d8de3450b",
            "value": "Generating train split: 100%"
          }
        },
        "96a51006e70245309565198d90e3df3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e814e996f0b4751922b39cca14fad42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5373135bed4e42dcbadd36d0ce9e1cf1",
            "max": 21155,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_708c55b46cee4e70a07b96db34987303",
            "value": 21155
          }
        },
        "a81e006a9a434b0492fda4a7f4218854": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab66a401e02f4383adea71df2e17f287": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ace092e6a80043f4ab0856da53c0fdfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b250960e874e409c95a2e3a98dc8eea3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b313ea122dc747aba1e9254d82ea4683": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df65b0d800464b1db87a2d72350ccd42",
            "placeholder": "​",
            "style": "IPY_MODEL_6d2c0784eb0a41f2851cef60709c312e",
            "value": " 21155/21155 [00:00&lt;00:00, 143599.76 examples/s]"
          }
        },
        "b33c134019a74eaca31344110bb3d511": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e14f675cc64640b01d8c2f761dd172": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba181c4d484f4f72a6001abf0db6d823": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccb8b35ff55542a08c1823101e00c36a",
            "max": 1752,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4e14f675cc64640b01d8c2f761dd172",
            "value": 1752
          }
        },
        "bad31a37d40d46baaab0bec2b8398367": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0a63384654347519ecc4d4bb4c36e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c54b56bf9ba746a388d54c3df6f36c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccb8b35ff55542a08c1823101e00c36a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccd13dbc9e544f64b145a452f542140a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a13e8eb621a4813a8907a8f43ed0ccd",
              "IPY_MODEL_9e814e996f0b4751922b39cca14fad42",
              "IPY_MODEL_8f1f1f79c9c243659e7a0eb145d91caf"
            ],
            "layout": "IPY_MODEL_66e10d9d5562441a810b7ea1605f4354"
          }
        },
        "d533b5a5a866427590cfffb81736e2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddeea3999ef24ff09ed597c4c8caca4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df0a3375c62b4a41937d98d314846052": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df65b0d800464b1db87a2d72350ccd42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28dc99742fc4d188a19b03bbb4c3a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ad6971ff6cd4d2bbe5a4ee1f1a0e296",
            "max": 21155,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96a51006e70245309565198d90e3df3a",
            "value": 21155
          }
        },
        "eac5b168727445f69cb6a7b82947d871": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b33c134019a74eaca31344110bb3d511",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddeea3999ef24ff09ed597c4c8caca4f",
            "value": 20
          }
        },
        "edb8f2f44d75474fa65a265db064b21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4784724a873c4917ae087733643b9fcc",
              "IPY_MODEL_ba181c4d484f4f72a6001abf0db6d823",
              "IPY_MODEL_74482e31fa4f4e328f77561f87713e8e"
            ],
            "layout": "IPY_MODEL_5afd7f33b63e4f138554a933585f246d"
          }
        },
        "edd52e9d9f24474f84c340c9b4a76300": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf5e36a239147acad70b12f0b491973": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a81e006a9a434b0492fda4a7f4218854",
            "placeholder": "​",
            "style": "IPY_MODEL_6c8b5105e5a145a8a832c6d25571d445",
            "value": "Creating json from Arrow format: 100%"
          }
        },
        "f3bcee2835824b129a48deb1764ab82a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fae95b24e0bd43f290991a2b445b488b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab66a401e02f4383adea71df2e17f287",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d533b5a5a866427590cfffb81736e2ea",
            "value": 3
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}