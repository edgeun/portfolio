{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ZtNLrVwMd0",
   "metadata": {
    "id": "63ZtNLrVwMd0"
   },
   "source": [
    "### Mistral-7B-Instruct-v0.1 Finetuning 실습\n",
    "- 한국어 기사-요약 데이터셋으로 미세 조정하여 한국어 기사를 요약하는 모델을 생성하고 ROUGE 지표로 평가하기\n",
    "- Instruct Following 형식으로 학습 데이터 정제 및 SFT Trainer(지도학습 파인튜닝)로 학습시키기\n",
    "- 데이터셋 출처: https://huggingface.co/datasets/daekeun-ml/naver-news-summarization-ko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16Qc6ODZlwTc",
   "metadata": {
    "id": "16Qc6ODZlwTc"
   },
   "source": [
    "### 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc4871c-e460-4d9d-ae6c-0a6450a8858e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440,
     "referenced_widgets": [
      "4c66f77d469649b0b68d12f933a4dc12",
      "5827f0ebe7954d38bef9f57617846520",
      "a9e11e035d2f440b83603d984f244d14",
      "e44601799f0945f093004db33899e16a",
      "7bbcb6a8620641f2b13620c379dd964f",
      "0f0673da69c24ab9a763f7d1a6cb1e74",
      "b273953ee88844cdbf3e9fe602786f59",
      "4db8c71017744238b25b976087fe6343",
      "be14f67989a2404cb64b87b74678ac91",
      "d25ca23240db4a1c8fe2b27bb7262ad1",
      "ad517791b17b47698e2b066abd7d731a",
      "475c4b8bdaf94c3199ddfca65ab8bfc0",
      "2d928d172469415cb56992a09f3a9a94",
      "ff2dc2a409394ec1a02e301d030165dc",
      "eb80059734e94e26a6721bf40347e6aa",
      "2994d63f43cb4f9284dccd38df0aa704",
      "f8cbf20943c1428fbb1bc1b09b000d3a",
      "d6a34264872d4723be597037d0b6561c",
      "5d84a5d7ffc542569d9df09a467389a2",
      "0c6e62d614994a77889ac56c3718cb71",
      "97c2c47cf5f54d908dbd652ccc82c342",
      "be2aa92a1be349a8bfdc9831ff1fece4",
      "01c207f1ce824232830b50b4928e6a97",
      "cc1357dc59c34df6a7f0b7fca8708201",
      "ac3ee647f4014f419e537f6aebdf7b30",
      "1f1403767e364454b078dca6334292bf",
      "784821af7eea4828a0be472c6a7e6b72",
      "7e051bd9d80d44678007f91efed5eb3d",
      "c2b5b28a2c6548a3a89aed5edf971756",
      "7343454392ff4a6a9c042702a65950e2",
      "b1448c3214d24aadac3253c2aaf930ad",
      "3b994eb904f04207998ba4ec4181cc12",
      "e258460f341747bc88f7522e4863b97c",
      "9fb250ea50f54dbe92b2cd21aa497624",
      "16924db6139b40b48721a4de07353c9a",
      "69fe323453f54a7ca160b06ad4fb7d34",
      "645f41e0f99d46928ad04c12408052f1",
      "e8b953e4dd4b426ca84a7f8997341deb",
      "30f1b44946d343048376dbcda8e62cc3",
      "b818d6ae2a6e41f487fbd8106e3046ad",
      "13fde4f3c44b490fb569a1432fe3de49",
      "22fd8c0f32e645f7aa4798c5edb56e16",
      "77ce76fad92448ed80d89e9a029ebcc6",
      "59ee1ddda0f64e0bad1c21bc76bead11",
      "2b9871bd7cbf4da4949196094b79dccd",
      "7802c4acb8a5479fbd952f46a79e8dba",
      "bee8d3ccc7104c1390d6fb51c19ffaca",
      "783ec182264b44858d8961e665063c39",
      "22e13edb76f64918969274d3d57bcd5a",
      "d4d7833e5b734b5bbf4e861a847de063",
      "7fbe99ee72f84ba08c0dd860924b6520",
      "1fcbb057e91b47a29eb4621e1c4b0fc1",
      "48c675317a554a38be4ba370877bfac0",
      "0b617fdbd00a4d25a80504ee08ffd1fc",
      "00ceef7f094247f0adcb6607b9f02bcd",
      "785778ae054d402cbce30c58ac03a6c9",
      "95024ea488024893afa7006409767c4c",
      "43bef4cc7c81476197cc6352aca6eaf8",
      "7466f6c2d485413195f4939df1e4fd99",
      "7dfe34201de34dcdbec6ae6d53b01aac",
      "646bffa3dd4c46da8a0d0b986a1e7fbe",
      "6e7c2a47c4104828a717d6df96ace93a",
      "85af1de86882496e8bdfc058b925dac7",
      "91949719aa6b4b80a819f57e91d8fc25",
      "1afcf75486014440be8e4ef18096d870",
      "b9b09c9a138c4b5cba642686918da5de",
      "58b12f4ed339476eae27c35bb22213b3",
      "bbc35c14e5ed49d3b4a0191641681997",
      "832f7747c05a45278a5ba0f8a339f839",
      "c450702c8d734fc6b9e16eb54248e3c3",
      "a7c3253afd89469389b2c6dc0fa19775",
      "923410ce0f894dec80a01149ff92d6b0",
      "df9a448838e4437886c892afe4a95a15",
      "d7cb4149cceb450798816dd3bc31be65",
      "ea69343bdb0f4f18a30a0763b6e198f8",
      "288d6c3ea4ab4520824bcd3b4aebf3f3",
      "29533299e08c4057b774e70c45fb413d"
     ]
    },
    "id": "cfc4871c-e460-4d9d-ae6c-0a6450a8858e",
    "outputId": "b6a23464-bf78-41f6-9ae7-92772fdc5a63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/485.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c66f77d469649b0b68d12f933a4dc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/787 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475c4b8bdaf94c3199ddfca65ab8bfc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv:   0%|          | 0.00/66.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c207f1ce824232830b50b4928e6a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.csv:   0%|          | 0.00/7.45M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb250ea50f54dbe92b2cd21aa497624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.csv:   0%|          | 0.00/8.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9871bd7cbf4da4949196094b79dccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/22194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785778ae054d402cbce30c58ac03a6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b12f4ed339476eae27c35bb22213b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2740 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터셋 로드 및 샘플링\n",
    "!pip install datasets -qqq\n",
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset(\"daekeun-ml/naver-news-summarization-ko\", split='train').shuffle().select(range(2000))\n",
    "eval_dataset = load_dataset(\"daekeun-ml/naver-news-summarization-ko\", split='validation').shuffle().select(range(200))\n",
    "test_dataset = load_dataset(\"daekeun-ml/naver-news-summarization-ko\", split='test').shuffle().select(range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JXYgMsKBl6Mw",
   "metadata": {
    "id": "JXYgMsKBl6Mw"
   },
   "outputs": [],
   "source": [
    "# 불필요한 컬럼 제거\n",
    "train_dataset = train_dataset.remove_columns(['date', 'category', 'press', 'title', 'link'])\n",
    "eval_dataset = eval_dataset.remove_columns(['date', 'category', 'press', 'title', 'link'])\n",
    "test_dataset = test_dataset.remove_columns(['date', 'category', 'press', 'title', 'link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l6Midm-cm8dO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l6Midm-cm8dO",
    "outputId": "9cadcd7f-61b0-4933-dd99-7e3051056db7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['document', 'summary'],\n",
      "    num_rows: 2000\n",
      "}) Dataset({\n",
      "    features: ['document', 'summary'],\n",
      "    num_rows: 200\n",
      "}) Dataset({\n",
      "    features: ['document', 'summary'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset, eval_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DiJR8OFGop_F",
   "metadata": {
    "id": "DiJR8OFGop_F"
   },
   "source": [
    "### 양자화 / 로라 설정 후 모델(양자화 장착) 및 토크나이저 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ef4bf-afc7-4c13-b910-3d5d1c5c2634",
   "metadata": {
    "id": "7d8ef4bf-afc7-4c13-b910-3d5d1c5c2634"
   },
   "outputs": [],
   "source": [
    "# 허깅페이스 로그인\n",
    "from huggingface_hub import login\n",
    "\n",
    "# 허깅페이스 허브 로그인\n",
    "token = \"****\"  # 허깅페이스 액세스 토큰 입력\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab55eb2e-a41a-4bb5-8572-2ac02320f22c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283,
     "referenced_widgets": [
      "19577fc3e2a84caa86db0ef71b7b055d",
      "7bd4cb9f6faa464a9e24fa4b42c71c31",
      "33b8d52fc8334f76886bc3a6fd60c0fb",
      "6d226f698008403c8da051a7b673cc00",
      "0d3fc5021991472cb9b3a35df053eb6c",
      "61e061b09a634343af6919e11f1ac45d",
      "ef484d9e35224ad2bfd065653147c226",
      "89b99d5e48554f2dbdb8e9840bf491c5",
      "88793893ed104e588fa5f3eb9b1f77f3",
      "931a7e253eb2442eac67d6f3b0b31a6f",
      "533c7a234003495abd2a7548b022adb9"
     ]
    },
    "id": "ab55eb2e-a41a-4bb5-8572-2ac02320f22c",
    "outputId": "2e668719-0658-4138-8fa6-7095cd4b7a44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19577fc3e2a84caa86db0ef71b7b055d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install bitsandbytes -qqq\n",
    "import torch\n",
    "import bitsandbytes\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model, PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# 4비트 양자화 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "\n",
    "# LoRA 설정\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    init_lora_weights=\"gaussian\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oSz5bOaSxpU4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "a2bfe4e1131448909479bd67a01f209f",
      "cfb8a40e52614794935d12fdf0ff6dfc",
      "11dc67e2b24a4135b91cf7ca204912c1",
      "0b11bef890d349dfa66bfa2afde4ec6f",
      "55245e4415724a2c854ad60a97140848",
      "36b921465e6d424faaaa6245f97626b7",
      "dc2dc514217547c3887e6a4fd87e57e7",
      "459e00ea067d4b158e18f5a3832b5f5d",
      "8611db4d3d904bfda4240104aed393d2",
      "a9d144dd7aba4184aa0d53c98a241034",
      "70252ae314d34f558f04e595ab184cb3",
      "17537375bd064aebaeaeef7c643b6969",
      "07bdeb73633c42438576a7589abe8cf2",
      "9b4d5e90d8d640b796c9359297b9fd81",
      "26e95b93285a4303afba6b3292f0b926",
      "f588afa7578244739cd3d61517ab2c13",
      "cdb2bec6ef3b48889ca8014026f971ee",
      "0f712546f8d04431bcc477a1fe58c4ae",
      "50679717459a40dc90bbdff739f3669c",
      "ccff2b84575c45da84d119a232b4d2a9",
      "eb6f2eddb1e440b98ce88daa173d7f3c",
      "99da04d7aaa64d00b5570f143faea659",
      "19dd7c52d62e4008946d10c2bb6c3692",
      "398725303f444a86bb495d2aba7df11b",
      "492d0a6ee8cf42f9b3cb467e14e79487",
      "da0d58ba41614466afee3307adcf6a0e",
      "9eae2a2f7aae43bb81a857f258b974d0",
      "cc20c74a066d4a65b70746e82fd5eedf",
      "586116d6be894d4cb33b55604038ebb0",
      "dbf2ba1f08c646369830a7629d339a86",
      "04346d04de934b10b0798c0b21a14382",
      "98ad9911e537438b87b348e83853962f",
      "b4936e94a8954ef580c12bedae183eb3",
      "9721fa2370f34311b81736922e403a1e",
      "e396e52d0cf44cafa82bf9210c173398",
      "a956868731744912b09269d82c5b9a83",
      "b247b53fd7044a689c1ed722bab6f51d",
      "4b4e089cbc6d4d4ba9e49e44f6699fe4",
      "136d6a7d735b4ec9b034d0dfae55ee80",
      "d8c7141faa234a88809d7cdd5b05012e",
      "988936b80cf74035823b60ef54520411",
      "29fe50b32d6b4a0eb6f8c36ebd03a07c",
      "b7616445d56c45c8956c67054a5267e5",
      "a6370eb636c84d5897d2900443fe627f",
      "1242d3d4ee4d4b7c8deec332420b3f73",
      "f36cb0c4c6b34a1c9e5643a3472f2e01",
      "d70d1db28f084399baaa5fba84fa40c4",
      "d82b5f2bd5bd4ad7a04465afe9c12636",
      "3a1d940bb36a46ba8f14619862b1897a",
      "1dae3750e47a4e48bd5f682e0044f483",
      "db83f96622064bbcadc2ecaac5be6d61",
      "01ffafe55edc40f999fe0f80869ad955",
      "29fbf3d41ae949768929e8ff01634278",
      "f3b75ca4e1d646ec82969a295001e8ad",
      "716db8af5e7b45168bcd67be54acdd8e",
      "c31f8b5554e5461c8d5965775933e973",
      "ac4ad915182b4a83911430d9fb581c87",
      "c2dc2d119e1e4e64a5009c741804cc80",
      "73123cfc118548d2a79dffd2240eba3d",
      "9846035c68f1491dae261edfe817810b",
      "6d614a48c0b441c5a1d58517e4181e9e",
      "b429444ed0d24d8ebde34647531dab23",
      "aa2395dd46f548bf84f4d0642082df72",
      "80171cac3c5c4efe898342dbbfdbac74",
      "d4789613c2c4415d833f10fc05d1a267",
      "08f1059c64bb4973b40a9f322e8604f0",
      "7ecca876c5e6441db7054c1a683ce18f",
      "ac664e56990b4db0b8a4e7a4a6b12d16",
      "bcf054ade16548b1ad6c9dd5af5ccc1d",
      "0cf53863d6ce44d2afabe766b23229c6",
      "f9e2e0c3cb1f45c58a2b38bb77bc68c8",
      "88d79e09f4e345a1a90a474c9ec00fa1",
      "00d44ef8aeec4e85971ffa5fadc184c8",
      "e6789c40ef8944a4ab919ee55ea3449d",
      "81ff23e15bb7470397ce56fc0da0b177",
      "21ce9fdbf1ca413fa25ae30210646cec",
      "a361a3faf27f454dbe042bdf26a4c9a8"
     ]
    },
    "id": "oSz5bOaSxpU4",
    "outputId": "0fa29c50-9db0-4562-a00e-7b2bcada2cd0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bfe4e1131448909479bd67a01f209f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17537375bd064aebaeaeef7c643b6969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19dd7c52d62e4008946d10c2bb6c3692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9721fa2370f34311b81736922e403a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1242d3d4ee4d4b7c8deec332420b3f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31f8b5554e5461c8d5965775933e973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ecca876c5e6441db7054c1a683ce18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 양자화 모델 준비\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\", torch_dtype=torch.float16)  # 양자화 장착해서 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FUAV2cp7okUy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "7154e4bc70bb4a8b903ee0d4393e1293",
      "2aae1f64161343cb93e800ba42dc66c8",
      "fca6b5babca447deb249e9e594ad1244",
      "a9806a63e47942abb94dbf139fecbcf9",
      "4cd3e34a95fb4ce6b4cd0396e61cf060",
      "55e0bec747684083918e2cee7fe4b3f4",
      "8890e6c240c944fc8ac2b36ee21286c3",
      "e47b6deac7094bfc846a407a23fe2737",
      "1e6920a7178b499ba3028d9e350d3f71",
      "3ec4c6de4c9a44dcad4c5aae53500256",
      "9ca84c28724b48d8bd008563c9845aa3",
      "c38d2099e954449da49971188cc3d57b",
      "99b4534d605b4009a1808130cc612180",
      "1278a3b5c21643688f4a3818f09636de",
      "ebb4b1687d904b4f9dca3b4b40a29594",
      "d176b65c215d45f195dc8ee6b157ee88",
      "43c1417d4d914485a0da6e877ddab492",
      "94ab2aa6a8c04188bff105efddc806ba",
      "02980fbbdadd45fab0850f763ac70d9d",
      "3fe7c6a9681641fea0203afc9ad26985",
      "51c8867e25294eb19f7a3305c346ce4e",
      "53042c5080854b42844a9f8852b9b27b",
      "ad6b8c4875614c5c8b27f81b5f53b6d2",
      "350b49dacf9a46e7899af87787d969e7",
      "29934af559704201bb4d6316d12f83df",
      "0237e78a0be44db680b44bb6ec0ec5de",
      "ca93c8b9df7141238f66639ad80861cd",
      "325b147e0ad849788b82d5b90ab0f9da",
      "20182dcbd09e47bbb0c46310bdda96e7",
      "bc5403a27dbd4c8bb58c8e74f5701958",
      "f11ec417fc42439da04481607679ef09",
      "ce1205d092bc41a1b63b7016b508eaef",
      "b350210313634537a1d5e4ed9e2f25b4",
      "f1fe5b93fb2f401085bffb081738532f",
      "1ed2d2ea21734a5bb892b5a3685604fe",
      "5a7482b0e36e41da8bbc11c30f7b3cfc",
      "0e062c8cd249452eb7cea096c9777a2f",
      "acd7931ad651484c8635fafbb1a15fd5",
      "c6edfe868982483591f28fc85593aea5",
      "7e670de9d9274de088c37fc19d6a4d69",
      "c11b5883f61e4cf9a51574ef7afb6893",
      "854e391171ba48d592d0b65fc304033e",
      "090af553c10446fba8bf7225174798ba",
      "6f9d27cbf5464c368fad1c0ccd43b6b9"
     ]
    },
    "id": "FUAV2cp7okUy",
    "outputId": "4dd81864-2ef8-4c54-e4b5-16cf0540de98"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7154e4bc70bb4a8b903ee0d4393e1293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38d2099e954449da49971188cc3d57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6b8c4875614c5c8b27f81b5f53b6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fe5b93fb2f401085bffb081738532f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 토크나이저 설정 및 준비\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # eos 토큰을 패딩 토큰으로 설정\n",
    "tokenizer.padding_side = 'right'  # 학습 시 패딩 방향 '오른쪽'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pma7YEhyR1lW",
   "metadata": {
    "id": "Pma7YEhyR1lW"
   },
   "source": [
    "### 데이터셋 대화형 포맷으로 변환 및 토큰화 (전처리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0440468-1698-4ec6-a8bd-b55635abee15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "2d60a71f4a604d9d9faa9895ffec7847",
      "9ffd8d0411564ebe8acd12d041f883d8",
      "0ad01e7ad7d149bc8862f8e9c8b1e21b",
      "e812b04e62364683929d584d2d2d9ad1",
      "d26287bfe5f74e919cfe0cc786f5aa19",
      "b961543efb354b2bbd943e9109e137ac",
      "74ccabc80fe4414985e2fc3b1f75f42c",
      "247290aac00047509a90ca0d861ef244",
      "62b9423761414b86803077ed2bd9e74b",
      "26805c8300d04776968d8c6da5968d54",
      "61acc41e60f046f59ca595716c4508bb",
      "5c9ff52deae140d196b86cb18a489b37",
      "a4551e09f7094a8e9a97f5da515b1e1a",
      "2365b39269eb43799d5bcb67d55f640a",
      "f159a0c1c96f455595582fbea501e2f1",
      "e6c71e8f2f2e45efad416a1342f8d516",
      "5f664a4a78614340bfeb5d208688be78",
      "d2c3ad80c146484da44049737c16c1c4",
      "f488f1f8d57f46e98fb9ce07a06bf000",
      "0a35c4b8a3164b2a92a91eb04298a6ca",
      "097b244520e447288c2fdf7aec9bf13a",
      "56277105425f42bd8fccc5f29cb398b2"
     ]
    },
    "id": "d0440468-1698-4ec6-a8bd-b55635abee15",
    "outputId": "cb5b05bd-4c0a-470b-d8cf-aa8d69fce114"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d60a71f4a604d9d9faa9895ffec7847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9ff52deae140d196b86cb18a489b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instruction 템플릿 정의\n",
    "def create_prompt_template(document):\n",
    "    return f\"\"\"아래 뉴스 기사를 요약해주세요:\n",
    "\n",
    "기사 내용:\n",
    "{document}\n",
    "\n",
    "요약: \"\"\"\n",
    "\n",
    "def create_completion_template(summary):\n",
    "    return f\"{summary}\\n\"\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def preprocess_function(examples):\n",
    "    prompts = [create_prompt_template(doc) for doc in examples[\"document\"]]\n",
    "    completions = [create_completion_template(summary) for summary in examples[\"summary\"]]  # instruction과 completion 생성\n",
    "\n",
    "    # 전체 텍스트 생성 (instruction + completion)\n",
    "    texts = [f\"[INST]{prompt}[/INST]{completion}\" for prompt, completion in zip(prompts, completions)]\n",
    "\n",
    "    # 토큰화\n",
    "    tokenized = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "    # labels 설정 (input_ids와 동일)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "# 데이터셋 전처리 적용\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)\n",
    "eval_dataset = eval_dataset.map(preprocess_function, batched=True, remove_columns=eval_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HEcCGn79vtFF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HEcCGn79vtFF",
    "outputId": "67998e57-164b-4ab7-973e-43c0882da761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 2000\n",
      "}) Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset, eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SjSLjimqRkEf",
   "metadata": {
    "id": "SjSLjimqRkEf"
   },
   "source": [
    "### 학습 어규먼트 설정 및 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LtCqN2TeFSeC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "LtCqN2TeFSeC",
    "outputId": "bae2534d-6fe3-4d60-ff27-fa4187ae311a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdgriii0606\u001b[0m (\u001b[33mdg-test\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250223_165218-iuk7p6sp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dg-test/Korean%20News%20Summarization/runs/iuk7p6sp?apiKey=77a08abc9cfd76e4b78603826bd7a863487240ac' target=\"_blank\">swept-armadillo-11</a></strong> to <a href='https://wandb.ai/dg-test/Korean%20News%20Summarization?apiKey=77a08abc9cfd76e4b78603826bd7a863487240ac' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dg-test/Korean%20News%20Summarization?apiKey=77a08abc9cfd76e4b78603826bd7a863487240ac' target=\"_blank\">https://wandb.ai/dg-test/Korean%20News%20Summarization?apiKey=77a08abc9cfd76e4b78603826bd7a863487240ac</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dg-test/Korean%20News%20Summarization/runs/iuk7p6sp?apiKey=77a08abc9cfd76e4b78603826bd7a863487240ac' target=\"_blank\">https://wandb.ai/dg-test/Korean%20News%20Summarization/runs/iuk7p6sp?apiKey=77a08abc9cfd76e4b78603826bd7a863487240ac</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb 설정\n",
    "import wandb\n",
    "wandb.login(key='77a08abc9cfd76e4b78603826bd7a863487240ac')\n",
    "run = wandb.init(project='Korean News Summarization', job_type='training', anonymous='allow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knKWswHPs-_Z",
   "metadata": {
    "id": "knKWswHPs-_Z"
   },
   "outputs": [],
   "source": [
    "# 콜레이터 설정\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)  # Causal LM 모델용 콜레이터 # MLM이 아니라 CLM 방식이므로 False 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851966c3-6648-4f4e-88d8-40043557a4be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "851966c3-6648-4f4e-88d8-40043557a4be",
    "outputId": "9a46174a-bd2c-4d59-9982-13dea81aa6b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/318.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install trl -qqq\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# 트레이너 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "\n",
    "    # 배치 크기 및 그래디언트 누적\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "\n",
    "    # 학습률 및 스케줄링\n",
    "    learning_rate=5e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "\n",
    "    # 옵티마이저 설정\n",
    "    optim=\"adamw_torch\",\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    # 평가 및 저장 전략\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    save_total_limit=2,\n",
    "\n",
    "    # 학습 최적화\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    # 로깅 설정\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    report_to=[\"wandb\"],\n",
    "\n",
    "    # 기타 최적화\n",
    "    dataloader_num_workers=2,     # 워커 수 감소\n",
    "    group_by_length=True,\n",
    "    remove_unused_columns=True,\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    # 추가 설정\n",
    "    ddp_find_unused_parameters=False,  # DDP 최적화\n",
    "    torch_compile=False,               # 컴파일 비활성화로 안정성 향상\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d5ac0-9b26-4e1e-9a4a-977076f3471d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "8196febfca5448bfafe2809e0b007638",
      "c58d880348d4414aae85bdd94ae7aa4b",
      "eedbf487f0314962a50ac84e66ef8b6c",
      "bf4352c8ca40496e8ddbc5ac2d75fe41",
      "c6d22d721c4b4b479a57d7eebf8d1060",
      "dfe86caed15c41efa8505b7e0916a91b",
      "87bf0e739f1d4ec69e0213d330858778",
      "3f7ee647edc346dd82554e026a1565c7",
      "b319ec76abf9480694289937271c0603",
      "9a780a5f50044876b41179b7a2a5235d",
      "1a21dbac8f8641b7b69974f1dfb2ac2a",
      "c9bbed1b1f70461b9106079e39e767a5",
      "3108269c064248ce808e94cb848c4fe1",
      "1c73bd395d5d4ce9999b74c4c0468e65",
      "94094a42945346afb7cfacc52d155f92",
      "a4f74c0d6d1e4c92a9755caf0dfb39f3",
      "57d64b509a9c40a1be7246a888d86793",
      "c6e98ae9c75749348b20297e22387656",
      "beefb0654f6a406da24e91bed9346e25",
      "81cf8651149141a9ac596d7294abeebf",
      "b9e8544843834b2b8647fed8e00cffd6",
      "2d02874b32c941318f3a81c2ba5b4b4c",
      "9cebab4f0b6c4fa0964a255eff4ec055",
      "009f9d2f2be840b49c9c630f12b3c1cd",
      "4cab47f001b44a1c91fd01a2a3c84ad2",
      "4e6ceae13ebb43e6b4ee4b74e687d078",
      "df91af156c9b4de2ba3b5e6519b31e2c",
      "b0e2d2b7b40240719a9791356da0ced1",
      "7a4d8e8c518949c08e50bb100940385f",
      "fd6b8dc1374241f8820dde0046d9d4b9",
      "b8343a3b5eb24009b5e1e7af5b64cfd0",
      "5b4f8889eaff4939b7ced949a19a5e8a",
      "095028fead734f87aefebddab486b302",
      "9fbea6d7986145989170618fb4219b9e",
      "ae0540650880409a904e79bf69cb5a75",
      "d71bd9771cde49979f05bb5b6edf7b2e",
      "b6b3ddca18e347c0b9801dad55450edf",
      "6b42d9dc5b2845298220db006a6ce146",
      "9bb1f38ef7a24a9b9d0017a0f6ca3840",
      "ef323390ed614b8797a1a14f86c8b106",
      "9f92cc07ad2848a9806258166d244ce3",
      "f27ec4fb09be4edbbce5abcc6596aa07",
      "4c9167310cb54941841bfa02245ca605",
      "ae9403785007411dbc858e771a31f476",
      "2b64aaf70f274261b48571de0d88d1b9",
      "b9600d659fb54186bd8f30059beed79d",
      "d1504894e47342018d5ab9e188bebf15",
      "43dbe04be9ac4ab99b5bf348e74a8aeb",
      "a9ce4e1a425c45d98deaf3ef62861a16",
      "a78911c4ba054ad98bd3a507a209c596",
      "256f32b5b22a4baaafd5e6183eec317b",
      "13716c11f82f446399d5897dde2dfefc",
      "f1309402ac48402986faadb8a59c3c46",
      "69187ab22a6449d09aada73118df735c",
      "2f87de43c59f42febd6edd1607b6d54b",
      "323ed3fade8f4216ba9ce20fa1b66bfb",
      "6da3cd25c186433789723e0ea37e526f",
      "581820f354104a81aef9f50996267972",
      "86a8eb5ae9bb4e22897d4bbae5c22505",
      "fd419a678af84e4ca81134a6f29a44d3",
      "5265b300031f4cafa83da4d8adc1e810",
      "9a73f3843abf4159a3637b37edb3cdef",
      "9c99ee948e3c455b8e97ec9038ec8a99",
      "eb18e2b6ffc643afa8a1190253b4345c",
      "92e982ef3af5416ca261181a1508f1c4",
      "b1a82a0e12f940b2b48c8d373a961865"
     ]
    },
    "id": "cb4d5ac0-9b26-4e1e-9a4a-977076f3471d",
    "outputId": "686236d0-e653-4c6c-a1c7-636206a74897"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8196febfca5448bfafe2809e0b007638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bbed1b1f70461b9106079e39e767a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cebab4f0b6c4fa0964a255eff4ec055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbea6d7986145989170618fb4219b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b64aaf70f274261b48571de0d88d1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323ed3fade8f4216ba9ce20fa1b66bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 트레이너 설정\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    peft_config=peft_config  # 로라 설정 SFTTrainer 내부에 적용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4y6eC-OCy4WG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "4y6eC-OCy4WG",
    "outputId": "e1aab825-f9ec-4b87-f4b3-6f2fa1e9549d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 10:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.627700</td>\n",
       "      <td>1.591480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.496900</td>\n",
       "      <td>1.527893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=1.5989828491210938, metrics={'train_runtime': 663.8642, 'train_samples_per_second': 3.013, 'train_steps_per_second': 0.188, 'total_flos': 4.3708833595392e+16, 'train_loss': 1.5989828491210938})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 실행\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1HygeQFqRpFt",
   "metadata": {
    "id": "1HygeQFqRpFt"
   },
   "source": [
    "### 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WVTQJsufN9Om",
   "metadata": {
    "id": "WVTQJsufN9Om"
   },
   "outputs": [],
   "source": [
    "!pip install rouge_score -qqq\n",
    "import numpy as np\n",
    "import torch\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def evaluate_model_metrics(model, tokenizer, test_dataset, batch_size=8):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)  # ROUGE 점수 계산 초기화\n",
    "\n",
    "    # 평가 결과 저장용 리스트\n",
    "    rouge_scores = {\n",
    "        'rouge1': [],\n",
    "        'rouge2': [],\n",
    "        'rougeL': []\n",
    "    }\n",
    "\n",
    "    # 모델을 평가 모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 배치 단위로 데이터 처리\n",
    "    num_batches = (len(test_dataset) + batch_size - 1) // batch_size  # 배치 개수 계산\n",
    "\n",
    "    for i in tqdm(range(num_batches), desc=\"Evaluating\"):  # 배치 단위 데이터 추출\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = min((i + 1) * batch_size, len(test_dataset))\n",
    "        batch_documents = test_dataset[batch_start:batch_end]\n",
    "\n",
    "        # 배치 프롬프트 생성\n",
    "        prompts = [\n",
    "            f\"[INST] 아래 뉴스 기사를 요약해주세요:\\n\\n기사 내용:\\n{doc['document']}\\n\\n요약: [/INST]\"\n",
    "            for doc in batch_documents\n",
    "        ]\n",
    "        references = [doc['summary'] for doc in batch_documents]\n",
    "\n",
    "        # 추론할 때 토크나이저 패딩 방향 설정 (generate() 사용 시)\n",
    "        tokenizer.padding_side = \"left\"  # ✅ 추론 시에는 left-padding 사용\n",
    "\n",
    "        # 입력을 토큰화 후 GPU로 이동\n",
    "        inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048).to(model.device)\n",
    "\n",
    "        # 모델 예측 (배치 처리)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=128, do_sample=True, temperature=0.7, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "        # 모델이 생성한 요약문 디코딩 (배치 단위 처리)\n",
    "        predicted_summaries = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        predicted_summaries = [pred.split(\"[/INST]\")[-1].strip() for pred in predicted_summaries]\n",
    "\n",
    "        # ROUGE 점수 계산 (배치 단위 처리)\n",
    "        for reference, predicted in zip(references, predicted_summaries):\n",
    "            scores = scorer.score(reference, predicted)\n",
    "            rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n",
    "            rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n",
    "            rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n",
    "\n",
    "    # 평균 ROUGE 점수 계산\n",
    "    avg_scores = {\n",
    "        'rouge1': np.mean(rouge_scores['rouge1']),\n",
    "        'rouge2': np.mean(rouge_scores['rouge2']),\n",
    "        'rougeL': np.mean(rouge_scores['rougeL'])\n",
    "    }\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"ROUGE-1: {avg_scores['rouge1']:.4f}\")\n",
    "    print(f\"ROUGE-2: {avg_scores['rouge2']:.4f}\")\n",
    "    print(f\"ROUGE-L: {avg_scores['rougeL']:.4f}\")\n",
    "\n",
    "    return avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xlokOTGCixpK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "8e3bede8a2914b9d993141c7e5a4a65a",
      "0a7932e882734d97ba139fe4b830bb1c",
      "3819a02d8fc04ad8bc0cf678dce9b137",
      "d6891d67f2424aa4b48e87d999e6299d",
      "7b865f6b25404827bf324fd266cd5433",
      "6f56c87501164c97bc85fc1276d0ff11",
      "78c84e9772bc431b8d6952e7bc20297c",
      "f2c8fc3e15504b7cb07d5849a6651d0f",
      "49889219a56d482d82e0e0757b143ed6",
      "a71f708cd61b4987bce66f95166bef27",
      "48d0cc6189314e858282109589a4b635"
     ]
    },
    "id": "xlokOTGCixpK",
    "outputId": "c7b1e36c-2f34-4b65-9af9-ff6ef62c2089"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3bede8a2914b9d993141c7e5a4a65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.4150\n",
      "ROUGE-2: 0.1951\n",
      "ROUGE-L: 0.3971\n"
     ]
    }
   ],
   "source": [
    "# test_dataset을 리스트로 변환\n",
    "test_data_list = test_dataset.to_list()\n",
    "\n",
    "# 평가 실행 (배치 크기 8로 설정)\n",
    "scores = evaluate_model_metrics(model, tokenizer, test_data_list, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VUoz3M4rRrnZ",
   "metadata": {
    "id": "VUoz3M4rRrnZ"
   },
   "source": [
    "### LoRA 모델 저장 및 허깅페이스 허브 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stLoHg0nGSEI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stLoHg0nGSEI",
    "outputId": "211ebb6e-16bb-46d0-a7e6-db57f3b2a88d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./mistral-finetuned/tokenizer_config.json',\n",
       " './mistral-finetuned/special_tokens_map.json',\n",
       " './mistral-finetuned/tokenizer.model',\n",
       " './mistral-finetuned/added_tokens.json',\n",
       " './mistral-finetuned/tokenizer.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LoRA 모델 저장\n",
    "trainer.model.save_pretrained(\"./mistral-finetuned\")\n",
    "tokenizer.save_pretrained(\"./mistral-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19511319-b113-40bd-917e-8027ea12ce8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272,
     "referenced_widgets": [
      "17af0246d45a47cd9d1a124f3bbbda87",
      "af52070846854f4b8e2167ffd003e9f4",
      "186cd3f3100b42eb95ff1bb9aece298e",
      "202290804da3404ba1441d3859411ef0",
      "970c4cc8fe3045f882547cdc6f80d448",
      "c8cb268a4a944b93972ffa54746b8035",
      "e103a10d3edb46aead531ac42f350020",
      "6e2b1a6c3df64839917218c42ad991c1",
      "189800f5fe8e4cff9018b354afe1bbf4",
      "cb19914dabd24faf8d5802792b8a401c",
      "a03a1e213cac43c5ad9cb647e6e9a528",
      "96704ec4c3924bc8a6ad6e7f2c917750",
      "d76463911c5249a58e49274137c4d581",
      "4b007330428a4d52b771c0715f9b5175",
      "415d05ebc27547f08a971894d4036123",
      "c0c4818701a646638ca0f8605fbca841",
      "94b3f7efef6949ab84b6faa8f54fb5f4",
      "f534c99fb285439294b8760382ac78b0",
      "4096fbd9475343b0b2f4b4603f6b42d0",
      "f86a23ed0d75484383b533a20a4ea371",
      "915b221c5c5e4716832c259e457e7336",
      "fab8b15cd96246c288ae6a742cc74b3b",
      "9785ed87d90c4d10ba4403a358c513af",
      "0b8cc3354ccc4d0583023c0c96b15785",
      "6ad23a2a6758483f9cae8bc8509ad898",
      "2c6910a4b9a44916800be88888f44062",
      "6aa5fe0e4dd74a7caa7eab578e71fecb",
      "fc1532b36a37453a91071ed90c19dc46",
      "898e7296fbbc4b898ce2936eeefabf0b",
      "4c64e0e97d014d5a834f46fbb39494ac",
      "121b1763bfc341c48f0716eabb8b118d",
      "aa613c1e802f4181bcf438e96dcb8ebd",
      "39756c9f9f8c4bb88cece49e81c460ea",
      "b35c19364e1041ee850e8311e20a117c",
      "26ab9476164744e7924ceedadad1b9b6",
      "31142a7f9e01444d938febdadb0cb9b8",
      "b7ee40a2da8a49d794c3635442d44ad8",
      "a40c1daf41834f4888ef896dc2673e5e",
      "3b2b39c41086461a8da207b4ea6e127c",
      "5efc48d270dc46c8ac0defa500fe1f1c",
      "b840ecf57f5f470da2344c1c7faa45d3",
      "2c19e073245243e8a6b4662d906772c7",
      "14a292ece87449d7bca8d9269150a236",
      "36695faf3fd04400a2f1e0d5b2e713fd",
      "9d65323a723545b3b455dd126ace4f94",
      "66f42417bd1e422b87ccd8c0936c9b68",
      "f6e6ce7d95b447a7a6f14c0e9a8d8629",
      "a31f01e7711f42da961b18436137c802",
      "ee537ad0b454486f9c646bd33ae2e636",
      "833f52047af54271ac5e28ea4ecdf4c0",
      "62e9b77f224241e4bf2d1137d37004c4",
      "52e773dec7d443bcb3a1f511ccb5a9f4",
      "27cfbca2e9c2420bb52307e30b946e9d",
      "efb9177af97a4303a327a4abf8572c97",
      "6cfeff52e0004ffba3ced8df82a61c97",
      "5e1c1e4437574c3cbb74814ed0a9c338",
      "991742bf3049407d889ada75255d17ae",
      "6ea9e09f49094c84a0ced4422e646e81",
      "91c5a0f01ffe4ee8b50e95bc61d30f72"
     ]
    },
    "id": "19511319-b113-40bd-917e-8027ea12ce8d",
    "outputId": "e5359396-78f7-4556-f763-3aee3a65535d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17af0246d45a47cd9d1a124f3bbbda87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:355: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f534c99fb285439294b8760382ac78b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898e7296fbbc4b898ce2936eeefabf0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efc48d270dc46c8ac0defa500fe1f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/edgeun/mistral-7b-instruct-v0.1-korean-news-summarizer/commit/c84753e68d104b75fba4c94d3f89ac74c3e7e488', commit_message='Upload tokenizer', commit_description='', oid='c84753e68d104b75fba4c94d3f89ac74c3e7e488', pr_url=None, repo_url=RepoUrl('https://huggingface.co/edgeun/mistral-7b-instruct-v0.1-korean-news-summarizer', endpoint='https://huggingface.co', repo_type='model', repo_id='edgeun/mistral-7b-instruct-v0.1-korean-news-summarizer'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hugging Face 로그인\n",
    "login()  # 또는 'huggingface-cli login' 실행 후 토큰 입력\n",
    "\n",
    "# LoRA 가중치 병합\n",
    "trainer.model = trainer.model.merge_and_unload()  # LoRA 병합\n",
    "\n",
    "# Hugging Face에 업로드할 모델 ID\n",
    "repo_id = \"edgeun/mistral-7b-instruct-v0.1-korean-news-summarizer\"\n",
    "\n",
    "# 병합된 모델 업로드\n",
    "trainer.model.push_to_hub(repo_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.push_to_hub(repo_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hXO_QXWaRu-6",
   "metadata": {
    "id": "hXO_QXWaRu-6"
   },
   "source": [
    "### 업로드한 모델 불러와서 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ThVfdCBF6u1s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThVfdCBF6u1s",
    "outputId": "37c5e6b1-fdae-4cc6-a296-d42433ea7f7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "icn8exZoJ-CT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850,
     "referenced_widgets": [
      "0598e9323a8f486eba1fee5c0a1dd9f3",
      "560fc2783d69493c9715d5679575b789",
      "073f53b3edf246a99fc195548e9caa7b",
      "ad3e6e64c67a4a26b386e6e842ed8e8f",
      "1c2f397d48434129aec3e063073dec7d",
      "537ffb27f32a41c18359d90da6e7d6c7",
      "69f0ac6810a743aa87bf769c0d6b8462",
      "f76535454cd74e9380bd529c02cde8f5",
      "16864fec2a244caab8570faa2aac0530",
      "43d03cb637f749bb91d7269ddecd5a0b",
      "49a52bc339224b1cafe7d42105719b11",
      "6b1b73cd3f684d7792136e03989012fd",
      "394fe5e8a8724269b4228a992c6ad5ae",
      "df6095a163fc4f5fa8befe81efa84964",
      "506f6d8859bf4c41948da43222c494fe",
      "ae7a653f6a774b9785416969e90a7a96",
      "59964a2f11894930bbc999429572f167",
      "c2c7706242ff4f478c82510f7131872c",
      "fd3f5245ddf04d128b30b6a766b0b77b",
      "de680ace8af24f9f8453d8ed165d57d6",
      "c4409f7185494d2b94812aedbead8987",
      "177e309f525148dda19b51bf8d7a7eac",
      "bcc819c6113a42b2a3b7471ea6958687",
      "e8845d0c213f406aa98edc3cac2ee40b",
      "095956aab6ce4773afb943327114c1c6",
      "4245bbc416b04d87b01fc6763dd12f73",
      "bf1cdcf7708b4aeabad5d1d01df9e68f",
      "85cfc9ac563d466a9edb337f5eac7cb4",
      "e3624f9a401148ee9ab4f9324a7b615d",
      "3792672023b04e59904bb2da25b123d2",
      "d3889c37fa7b4328a1d2dbfb50b3db89",
      "5941724b3ad347a3b31fd3492357b846",
      "f988e958caa4487d8a793a25578d90f2",
      "da835a2df8ac44b69921b3bb223bd69d",
      "3294d4d4b93a40c4bdf993cca6f5adb0",
      "25daea25e953468d9a881833019947e3",
      "1584f7cb1bb54ae99ae61671afdc2046",
      "4acb5e27aaed4ddba54520a4bc3719f5",
      "d301719e180244559b1c24e064215650",
      "2d328fa996854c3e83ea7d42a91010ee",
      "04460a17e8494f9db094a03b26d673bd",
      "b2fb3acc94204ab1b04adaf5edac39a3",
      "45b80de5416a415b856bba44314fc87d",
      "9b088b475aeb453e8cc949706e2c5302",
      "5bcbdfc476544f19be09a70e5f19f75d",
      "54695f61d38842e89a9818a8058c4af9",
      "870b12416e9d4f038eb62c651c8905f1",
      "e4b7cb56317f44e5a81bb6a480a94331",
      "4e22350aa0214494a49ab36ec2d0b90e",
      "50cdace134d24063a378401d0a75d9b4",
      "02229a3d9fef4ca69f5dd45cc8f38276",
      "4d16abec3adc4d71b30608d7fdd8b3be",
      "7fccc14a795240229cd212ee119979a7",
      "d858aa2c46ad47cdbfdfed58032a6146",
      "6cf97e36c82a4c2eb5430f746cc4baa5",
      "d2f5e06146c6402fb032db7d76e9b436",
      "65b156a5382e406599f8d6583270b764",
      "3cca69a3d1f4427b8d457e2434c247c8",
      "9c4cc11bc1db46339af1728098c17a20",
      "df2ebe23b23d4f6693a57b97965f424e",
      "f18b1f456a6443c0b56fae8151651fa9",
      "bb6519cb21094bc982d78cb92fd51235",
      "6362fe981c934fffbeacea81babe95a6",
      "126e9ca666e241788e5bde04ce45e2b6",
      "0cab6dad70604f71a970989312cf5ba2",
      "4f6c33c16bed485cbd853d21795d25c1",
      "53af22b52a6742bba792ae1efec43957",
      "0e642591737e49948ce8c187e4e189b4",
      "0df40188548f4352be3758e45b370a3a",
      "6d59cc0456a34626b96c94a7900913a5",
      "813f50f68bf442a7ab7394f5b5bc14fc",
      "6333ca8636564a31a2ab84c2875627e1",
      "38307c9ddf8e4a7a8b98fbde2b096e2f",
      "5a6eddcc1f5e4d109e5b1f2020492c71",
      "7f26cc5c273f4e53b677dee65aad02ab",
      "f2e95b48fe08477196ea9a4fba10c6c4",
      "af972df87b8342cd84e1de205050a7e0"
     ]
    },
    "id": "icn8exZoJ-CT",
    "outputId": "d04c0f7c-9130-435c-9119-7efcf7792c35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0598e9323a8f486eba1fee5c0a1dd9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1b73cd3f684d7792136e03989012fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc819c6113a42b2a3b7471ea6958687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da835a2df8ac44b69921b3bb223bd69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcbdfc476544f19be09a70e5f19f75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f5e06146c6402fb032db7d76e9b436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.51M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53af22b52a6742bba792ae1efec43957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): MistralRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bitsandbytes\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "my_model_id = \"edgeun/mistral-7b-instruct-v0.1-korean-news-summarizer\"\n",
    "\n",
    "# 모델 불러오기\n",
    "model = AutoModelForCausalLM.from_pretrained(my_model_id, device_map=\"auto\")\n",
    "\n",
    "# 토크나이저 불러오기\n",
    "tokenizer = AutoTokenizer.from_pretrained(my_model_id)\n",
    "\n",
    "# 패딩 토큰 설정\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"  # 추론 시 패딩 방향 '왼쪽'\n",
    "\n",
    "# 모델을 추론 모드로 변경\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zCEH3euxYKnn",
   "metadata": {
    "id": "zCEH3euxYKnn"
   },
   "outputs": [],
   "source": [
    "# 추론 함수\n",
    "def generate_summary(article):\n",
    "    prompt = f\"[INST] 아래 뉴스 기사를 요약해주세요:\\n\\n기사 내용:\\n{article}\\n\\n요약: [/INST]\"\n",
    "\n",
    "    # 토큰화\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "    # 모델 추론\n",
    "    output = model.generate(**inputs, max_new_tokens=128, num_beams=3, do_sample=True, temperature=0.7)\n",
    "\n",
    "    # 결과 디코딩\n",
    "    summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    summary = summary.split(\"[/INST]\")[-1].strip()  # 요약문만 출력\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SO8WG2dlYNOi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SO8WG2dlYNOi",
    "outputId": "d01070b5-c16f-454f-aa63-340ad18972e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 요약: 10일 대형마트 업계에 따르면 오곡밥 주재료인 붉은팥, 찹쌀, 서리태, 수수, 차조 등 국산 재료 값이 급등하자 일부 품목을 수입산으로 대체하고 있다. 특히 잡곡밥에 들어가는 붉은팥 가격이\n"
     ]
    }
   ],
   "source": [
    "# 테스트 실행\n",
    "article = \"\"\"\n",
    "\n",
    "정월대보름(2월12일)을 앞두고 서민들의 시름이 깊어지고 있다.\n",
    "고물가 장기화에 장바구니 가격 부담이 갈수록 커지는 가운데 정월대보름에 챙겨먹는 오곡밥과 부럼 등 재료 가격마저 크게 올랐기 때문이다. 대형마트는 국산 재료 값이 급등하자 일부 품목을 수입산으로 대체하고 있다.\n",
    "10일 대형마트 업계에 따르면 오곡밥 주재료인 붉은팥, 찹쌀, 서리태, 수수, 차조 등 국산 잡곡 시세가 일제히 상승했다.\n",
    "특히 잡곡밥에 들어가는 붉은팥 가격이 전년 대비 50%가량 뛰었고 찹쌀도 23% 이상 급등했다. 부럼 재료인 은행과 땅콩 가격 역시 17%가량 올랐다. 국산 건나물도 상황은 마찬가지다.\n",
    "호박과 고구마순의 가격이 각각 20%, 10% 이상 뛰었고 기획상품으로 내놓는 건나물 4종 세트 역시 전년 대비 평균 5~10% 올랐다.\n",
    "유통업계에서는 정월대보름 주요 품목 가격이 오른 이유로 재배 면적 축소에 따른 생산량 감소, 폭염 등 이상기후로 인한 작황 부진, 고물가 장기화에 집밥 수요 급증 등의 영향 등을 꼽고 있다.\n",
    "이에 따라 대형마트들은 고객들의 장바구니 물가 부담을 덜어주기 위해 일부 품목을 수입산으로 대체하고 있다.\n",
    "붉은팥과 호두, 땅콩 등이 대표적이다.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "summary = generate_summary(article)\n",
    "print(\"뉴스 요약:\", summary)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
